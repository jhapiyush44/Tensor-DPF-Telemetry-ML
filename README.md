---
title: DPF Soot Load API
emoji: ðŸš—
colorFrom: blue
colorTo: green
sdk: docker
app_port: 7860
---




# Vehicle Telemetry ML Pipeline

A complete end-to-end Machine Learning system that generates synthetic vehicle telemetry data, performs advanced feature engineering, trains predictive models, and deploys them via a FastAPI inference service. This pipeline predicts soot load levels and regeneration requirements for vehicle exhaust systems.

---

## Architecture Overview

The system follows a clean, modular architecture with four main stages:

```
Data Generation â†’ Feature Engineering â†’ Model Training â†’ API Deployment
     â†“                    â†“                    â†“                â†“
generate_data.py  feature_engineering.py    train.py      uvicorn (FastAPI)
     â†“                    â†“                    â†“                â†“
CSV files         Parquet features       Trained models    HTTP endpoints
```

**Data Flow:**
1. **Data Generation** (`generate_data.py`): Creates synthetic telemetry, maintenance, and trip data
2. **Feature Engineering** (`feature_engineering.py`): Transforms raw data into ML-ready features
3. **Model Training** (`train.py`): Trains RandomForest models for regression and classification
4. **API Deployment** (`api/app.py`): Serves real-time predictions with FastAPI

---

## Data Generation Explanation

The data generation module creates realistic vehicle telemetry data simulating multiple vehicles over an extended period.

**Configuration Parameters:**
- **N_VEHICLES**: 30 vehicles in the fleet
- **DAYS**: 90 days of historical data
- **FREQ**: 1-minute measurement frequency (measurements taken every minute)

**Total Rows Calculation:**
```
Rows per vehicle = DAYS Ã— Hours per day Ã— Minutes per hour
Rows per vehicle = 90 Ã— 24 Ã— 60 = 129,600 rows
Total dataset = 129,600 rows Ã— 30 vehicles = 3,888,000 rows (~3.9M)
```

**Generated Files:**

| File | Purpose | Rows | Columns |
|------|---------|------|---------|
| `telemetry.csv` | Raw sensor measurements (pressure, temperature, emissions) | ~3.9M | 8 |
| `maintenance.csv` | Maintenance events and schedules | Variable | 5 |
| `trips.csv` | Trip-level aggregations with distance and duration | ~2,700 | 6 |

These files form the foundation for feature engineering and model training.

---

## Memory/RAM Optimization

The default configuration (30 vehicles, 90 days, 1-minute frequency) requires moderate computational resources. Use this guide to adjust data generation parameters based on your available RAM.

**Recommended Configurations by Available RAM:**

| RAM | Vehicles | Days | Frequency | Total Rows | Notes |
|-----|----------|------|-----------|-----------|-------|
| **16GB** | 30 | 90 | 1 min | 3.9M | Full dataset, recommended |
| **16GB** | 50 | 90 | 1 min | 6.5M | Large-scale testing |
| **8GB** | 15 | 90 | 1 min | 1.95M | Comfortable processing |
| **8GB** | 10 | 60 | 1 min | 864K | Conservative approach |
| **4GB** | 5 | 30 | 5 min | 216K | Minimal dataset |
| **4GB** | 10 | 7 | 10 min | 100.8K | Very limited resources |

**How to Adjust:**
Edit the configuration in `data_generation/generate_data.py`:

```python
N_VEHICLES = 30  # Reduce to 15 or 10
DAYS = 90        # Reduce to 30 or 60
FREQ = "1min"    # Change to "5min" or "10min"
```

**General Guidelines:**
- Reducing `DAYS` has the largest impact on dataset size
- Increasing `FREQ` (e.g., from 1 min to 5 min) reduces rows by 5x
- Start conservative and increase if you have headroom

---

## Clean Restart Instructions

If you need to reset the pipeline and regenerate all data, follow these steps to clean your workspace completely.

**Why Clean Restart is Necessary:**
- Old data files may contain obsolete schemas or configurations
- Cached model artifacts can cause loading errors with updated feature sets
- Parquet format can cache schema information, causing conflicts
- Starting fresh ensures reproducibility and prevents subtle bugs

**Clean Restart Steps:**

```powershell
# Windows PowerShell

# Delete generated data files
Remove-Item -Path "data\*.csv" -Force
Remove-Item -Path "data\*.parquet" -Force

# Delete trained models
Remove-Item -Path "models\*.pkl" -Force
Remove-Item -Path "models\*.joblib" -Force
Remove-Item -Path "models\metrics.json" -Force

# Verify cleanup
Get-ChildItem -Path data\
Get-ChildItem -Path models\
```

**Linux/Mac Equivalent:**

```bash
# Delete generated data files
rm -f data/*.csv data/*.parquet

# Delete trained models
rm -f models/*.pkl models/*.joblib models/metrics.json

# Verify cleanup
ls -la data/
ls -la models/
```

After cleanup, proceed with fresh data generation (see **Step-by-Step Pipeline Commands** below).

---

## Setup Instructions

Before running the pipeline, set up your Python environment with all required dependencies.

**Step 1: Create Virtual Environment**

**Windows:**
```powershell
python -m venv venv
.\venv\Scripts\Activate.ps1
```

**Linux/Mac:**
```bash
python -m venv venv
source venv/bin/activate
```

**Step 2: Activate Virtual Environment**

Verify your virtual environment is active (you should see `(venv)` in your terminal prompt).

**Step 3: Install Dependencies**

```bash
pip install --upgrade pip
pip install -r requirements.txt
```


---

## Step-by-Step Pipeline Commands

Execute these commands in sequence to complete the ML pipeline. Each step builds on the previous one.

### Step 1: Generate Synthetic Data
**Purpose:** Create raw vehicle telemetry, maintenance, and trip data  
**Input:** None  
**Output:** `data/telemetry.csv`, `data/maintenance.csv`, `data/trips.csv`  
**Approximate Time:** 30-60 seconds

```bash
python data_generation/generate_data.py
```

Expected output:
```
Generated 3,888,000 telemetry records
Generated 450 maintenance records
Generated 2,700 trip records
âœ“ Data generation complete
```

### Step 2: Feature Engineering
**Purpose:** Transform raw data into ML-ready features with temporal aggregations  
**Input:** `data/telemetry.csv`, `data/maintenance.csv`, `data/trips.csv`  
**Output:** `data/features.parquet`  
**Approximate Time:** 2-5 minutes

```bash
python pipeline/feature_engineering.py
```

Expected output:
```
Loading data files...
Engineering features...
Computing rolling statistics...
Computing lag features...
âœ“ Features saved to data/features.parquet
Features shape: (3,888,000, 42)
```

### Step 3: Train Models
**Purpose:** Train RandomForest models for soot load prediction and regen classification  
**Input:** `data/features.parquet`  
**Output:** `models/regressor.pkl`, `models/classifier.pkl`, `models/metrics.json`, `models/feature_cols.pkl`
**Approximate Time:** 5-15 minutes

```bash
python models/train.py
```

Expected output:
```
Loading features...
Splitting data (80/20 train/test)...
Training soot load regressor...
Training regen classifier...
Evaluation metrics saved
âœ“ Model training complete
```

### Step 4: Launch API Server
**Purpose:** Start FastAPI server for real-time inference  
**Input:** `models/regressor.pkl`, `models/classifier.pkl`  
**Output:** HTTP server on `http://localhost:8000`  
**Approximate Time:** Immediate startup

```bash
uvicorn api.app:app --reload
```

Expected output:
```
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
INFO:     Application startup complete
```

Visit the interactive API docs at: **http://localhost:8000/docs**

---

## API Usage

Once the API server is running, you can make HTTP requests to the following endpoints.

### 1. Health Check
Verify that the API and models are ready for inference.

**Endpoint:** `GET /health`

**Example Request:**
```bash
curl http://localhost:8000/health
```

**Response:**
```json
{
  "status": "ok",
  "reg_model_loaded": true,
  "clf_model_loaded": true,
  "timestamp": "2026-02-10 10:59:08.645757"
}
```
### 2. Model Info

Returns metadata about the currently loaded models, including evaluated performance.

**Endpoint:** `GET /model/info`

**Example Response:**
```json
{
  "model_type": "RandomForest",
  "regression": {
    "mae": 0.034,
    "r2": 0.87
  },
  "classification": {
    "accuracy": 0.78,
    "precision": 0.82,
    "recall": 0.75,
    "f1": 0.78
  },
  "feature_count": 17,
  "timestamp": "2026-02-10T10:17:05.747Z"
}
```

### 3. Single Prediction â€” Soot Load

Predict soot load percentage for a single vehicle measurement.

**Endpoint:** `POST /predict/soot-load`

**Request Body:**
```json
{
  "engine_load": 0.6,
  "rpm": 2000,
  "speed": 60,
  "exhaust_temp_pre": 500,
  "exhaust_temp_post": 470,
  "flow_rate": 50,
  "ambient_temp": 30,
  "diff_pressure": 10,
  "temp_roll_mean_10": 480,
  "temp_roll_mean_60": 470,
  "temp_delta": 30,
  "minutes_since_regen": 120,
  "idle_ratio_30": 0.1,
  "high_load_ratio_30": 0.5
}

```

**Response:**
```json
{
  "soot_load_percent": 22.17,
  "confidence_interval": 3.45,
  "regen_recommended": false
}
```

### 4. Batch Predictions
Predict soot load and regeneration needs for multiple measurements in one request.

**Endpoint:** `POST /predict/batch`

**Request Body:**
```json
{
  "measurements": [
  {
    "engine_load": 0.60,
    "rpm": 2000,
    "speed": 55,
    "exhaust_temp_pre": 510,
    "exhaust_temp_post": 480,
    "flow_rate": 45,
    "ambient_temp": 30,
    "diff_pressure": 10,
    "temp_roll_mean_10": 500,
    "temp_roll_mean_60": 490,
    "temp_delta": 30,
    "minutes_since_regen": 100,
    "idle_ratio_30": 0.1,
    "high_load_ratio_30": 0.5
  },
  {
    "engine_load": 0.85,
    "rpm": 2800,
    "speed": 85,
    "exhaust_temp_pre": 620,
    "exhaust_temp_post": 580,
    "flow_rate": 65,
    "ambient_temp": 33,
    "diff_pressure": 25,
    "temp_roll_mean_10": 610,
    "temp_roll_mean_60": 600,
    "temp_delta": 40,
    "minutes_since_regen": 300,
    "idle_ratio_30": 0.01,
    "high_load_ratio_30": 0.85
  }
]
}
```

**Response:**
```json
{
  "predictions": [
    {
      "soot_load_percent": 22.17,
      "confidence_interval": 3.50,
      "regen_recommended": false
    },
    {
      "soot_load_percent": 54.74,
      "confidence_interval": 4.10,
      "regen_recommended": true
    }
  ]
}
```

---


## Testing & CI (Continuous Integration)

To ensure API correctness without committing model artifacts to GitHub, the test suite dynamically generates lightweight dummy models.

The CI workflow will:
- create dummy RandomForest models if none are present
- validate API responses
- run unit and integration tests

This ensures:
âœ” CI builds quickly  
âœ” tests simulate production behavior  
âœ” no large binaries (.pkl) are stored in source control

Add this to `.gitignore`:
```
models/.pkl
models/metrics.json
data/
```


### Interactive API Documentation
FastAPI automatically generates interactive Swagger documentation:
- **Swagger UI:** http://localhost:8000/docs
- **ReDoc:** http://localhost:8000/redoc

Use these interfaces to test endpoints directly from your browser with auto-complete and request validation.

---

## Design Decisions

This section explains key architectural and technical choices made in the system design.

### Why Apache Parquet for Features?

**Decision:** Store engineered features in Parquet format instead of CSV

**Rationale:**
- **Compression:** Parquet reduces file size by 70-80% compared to CSV (4GB â†’ 0.8GB)
- **Performance:** 10-50x faster read times for analytical queries
- **Type Safety:** Preserves data types (float32, int64) without re-parsing
- **Columnar Storage:** Enables efficient feature subset loading
- **Streaming:** Supports lazy evaluation for large datasets

**Trade-off:** Requires `pyarrow` dependency; not human-readable. Mitigated by using CSV for raw data (easier inspection).

### Why Time-Based Train/Test Split?

**Decision:** Split data by timestamp (80% earlier data, 20% recent data) instead of random split

**Rationale:**
- **Realistic Evaluation:** Simulates real-world scenario where you train on historical data and predict future
- **Prevents Data Leakage:** Temporal dependencies within vehicle trips stay together
- **Trend Detection:** Tests model's ability to handle temporal patterns
- **Maintenance Cycles:** Captures degradation patterns that emerge over time

**Alternative Considered:** Random stratified split (not suitable for time-series data)

### Why Compute Features Inside API?

**Decision:** API accepts raw inputs and computes features on-the-fly instead of requiring pre-computed features

**Rationale:**
- **Consistency:** Same feature computation logic used during training and inference
- **Simplicity:** Clients send raw sensor values; API handles transformation
- **Flexibility:** Easy to update feature logic without client changes
- **Portability:** Models remain self-contained with their feature requirements

**Trade-off:** Slight latency increase (typically <50ms for single prediction); mitigated by batch endpoint for bulk requests.

---

## ðŸš€ Optional Cloud Deployment (Hugging Face Spaces)

This project has also been deployed on Hugging Face Spaces as a Dockerized FastAPI service for demonstration purposes.

### Live URLs

**Health check:**
```
GET https://jhapiyush44-tensor-dpf-telementry-ml.hf.space/health
```

**Swagger UI:**
```
https://jhapiyush44-tensor-dpf-telementry-ml.hf.space/docs
```

### Current Status

| Endpoint | Status | Notes |
|----------|--------|-------|
| `GET /health` | âœ… Works | API running |
| `GET /model/info` | âœ… Works | Model metadata available |
| `POST /predict/soot-load` | âš  May fail | Model training during build exceeds memory |
| `POST /predict/batch` | âš  May fail | Same reason |

### Why POST endpoints may fail

During Docker build, the container:
- Generates synthetic data (~3.9M rows)
- Performs feature engineering (rolling windows, groupby ops)
- Trains RandomForest models

This requires >4GB RAM.

The free Hugging Face Spaces environment has limited memory, so the training step may be killed by the system:
- Exit code 137 (OOMKilled)

As a result, models are not created and prediction endpoints return:
```
503 Models not loaded
```

**This does NOT affect local usage:**
- Locally: Full dataset, full training, all endpoints work correctly
- The issue is only related to limited cloud build resources

### ðŸ”§ How to enable POST endpoints on Hugging Face (if needed)

If deployment with working predictions is required, apply these steps:

**Step 1 â€” Reduce dataset size for container training**

In `generate_data.py`, use environment variables:
```python
N_VEHICLES = 5
DAYS = 14
FREQ = "5min"
```

This reduces memory usage by ~100x.

**Step 2 â€” Reduce training cost**

In `models/train.py`:
```python
n_estimators = 20
n_jobs = 1
```

Prevents parallel memory spikes.

**Step 3 â€” Train models during Docker build**

Add to `Dockerfile`:
```dockerfile
RUN python data_generation/generate_data.py && \
    python pipeline/feature_engineering.py && \
    python models/train.py
```

This generates models inside the container so POST endpoints work.

**After these changes:**
- Models load successfully
- POST endpoints return predictions
- Space runs fully end-to-end

---

## Project Structure

```
Tensor Internship/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ .gitignore                         # Git ignore rules
â”‚
â”œâ”€â”€ data/                              # Data directory
â”‚   â”œâ”€â”€ telemetry.csv                  # Raw sensor data (~3.9M rows)
â”‚   â”œâ”€â”€ maintenance.csv                # Maintenance events
â”‚   â”œâ”€â”€ trips.csv                      # Trip aggregations
â”‚   â””â”€â”€ features.parquet               # Engineered features (generated)
â”‚
â”œâ”€â”€ data_generation/
â”‚   â””â”€â”€ generate_data.py               # Synthetic data generator
â”‚                                      # Creates telemetry, maintenance, trips
â”‚
â”œâ”€â”€ pipeline/
â”‚   â””â”€â”€ feature_engineering.py         # Feature transformation & aggregation
â”‚                                      # Converts CSV â†’ Parquet with ML features
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ train.py                       # Model training script
â”‚   â”‚                                  # Trains RandomForest regresssor/classifier
â”‚   â”œâ”€â”€ soot_load_model.pkl            # Trained soot load predictor (generated)
â”‚   â”œâ”€â”€ regen_classifier.pkl           # Trained regen classifier (generated)
â”‚   â””â”€â”€ metrics.json                   # Model performance metrics (generated)
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_features.py               # Feature engineering unit tests
â”‚
â””â”€â”€ api/
    â”œâ”€â”€ app.py                         # FastAPI application
    â”‚                                  # Endpoints: /health, /predict/soot-load, /predict/batch
    â””â”€â”€ __pycache__/                   # Python cache (auto-generated)
```

**Directory Descriptions:**
- **data/**: Input/output for data generation and feature engineering
- **data_generation/**: Scripts for synthetic data creation
- **pipeline/**: Feature engineering and data transformation logic
- **models/**: Training scripts and serialized model artifacts
- **api/**: FastAPI application for inference deployment
- **tests/**: Unit tests and validation scripts

---

## Tech Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Language** | Python 3.8+ | Core implementation |
| **Data Processing** | pandas | Data manipulation & aggregation |
| **ML Framework** | scikit-learn | RandomForest models & metrics |
| **API Framework** | FastAPI | HTTP endpoints & inference |
| **Model Serialization** | joblib | Save/load trained models |
| **Data Format** | Apache Parquet | Efficient feature storage |
| **Data Format** | CSV | Raw data interchange |

**Key Versions:**
- pandas â‰¥ 1.3.0 (for performance and API)
- scikit-learn â‰¥ 1.0.0 (RandomForest stability)
- FastAPI â‰¥ 0.95.0 (async support)
- pyarrow â‰¥ 8.0.0 (Parquet support)

---

## Summary

This end-to-end ML pipeline demonstrates a complete workflow for building, training, validating, and deploying vehicle telemetry models:

âœ“ **Data:** Generates ~3.9M rows of realistic synthetic telemetry  
âœ“ **Features:** Engineers advanced time-series features  
âœ“ **Models:** Trains two RandomForest models (regression + classification)  
âœ“ **Uncertainty:** Provides confidence interval estimates on predictions  
âœ“ **Deployment:** Serves predictions via FastAPI endpoints  
â–¸ Supports `/health`, `/model/info`, `/predict/soot-load`, `/predict/batch`  
âœ“ **Robustness:** CI-safe model loading  
âœ“ **Testing:** Unit and API tests with dummy models  
âœ“ **Docker:** Fully containerized for reproducible deployment



**Next Steps:**
1. Follow the **Setup Instructions** to configure your environment
2. Execute the **Step-by-Step Pipeline Commands** in order
3. Test endpoints using the **API Usage** section
4. Customize parameters in config files based on your hardware

For questions or issues, refer to the relevant script documentation or test files.

---

**Last Updated:** February 2026  
**Status:** Production-ready
